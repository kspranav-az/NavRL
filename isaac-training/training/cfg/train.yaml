defaults:
  - _self_
  - drone
  - ppo
  - sim

headless: False  # Make sure visual rendering is enabled
device: "cuda:0"
seed: 101

# Total Training Length
max_frame_num: 12e8 # max frame 
eval_interval: 1000 # evaluate the policy for every N training steps
save_interval: 1000

# Training Environment
env:
  num_envs: 9 # Reduced to 9 environments (3x3 grid) for better obstacle management
  max_episode_length: 2200
  env_spacing: 15.0  # Increased spacing for better drone separation and obstacle placement
  num_obstacles: 8   # Reduced obstacles for better drone visibility and training
  hover_assistance: True  # Enable hover assistance for untrained policies
  # Quick toggle: set to False to disable hover assistance
  # Or set environment variable: DISABLE_HOVER_ASSISTANCE=true

env_dyn:
  num_obstacles: 5  # Reduced dynamic obstacles for better training stability
  vel_range: [0.5, 1.5]
  local_range: [5.0, 5.0, 4.5]

viewer:
  eye: [8., 8., 8.]    # Very close view - should definitely see drones
  lookat: [0., 0., 2.]  # Looking directly at center drone
  resolution: [1280, 720]  # Reduced resolution for better performance

logger:
  backend: tensorboard  # or "csv"
  log_dir: logs
  exp_name: NavRL
